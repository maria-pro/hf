{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-29T03:48:25.970090Z",
     "start_time": "2024-07-29T03:48:25.591811Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T04:07:01.933363Z",
     "start_time": "2024-07-29T04:07:01.930623Z"
    }
   },
   "cell_type": "code",
   "source": "folder=\"/Volumes/TOSHIBA EXT/parks_all/fca_cutoff_1100/\"",
   "id": "ae50396c4f8d059d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T03:53:32.275582Z",
     "start_time": "2024-07-29T03:53:32.222983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes=[]\n",
    "for filename in os.listdir(folder):\n",
    "    if (filename.endswith(\".csv\")):\n",
    "        filename_path=os.path.join(folder,filename)\n",
    "        df_ind=pd.read_csv(filename_path)\n",
    "        \n",
    "    df.append(df_ind)"
   ],
   "id": "a13072cf04859c7",
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb0 in position 37: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (filename\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[1;32m      4\u001B[0m     filename_path\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(folder,filename)\n\u001B[0;32m----> 5\u001B[0m     df_ind\u001B[38;5;241m=\u001B[39m\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m df\u001B[38;5;241m.\u001B[39mappend(df_ind)\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1898\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1895\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m   1897\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1898\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmapping\u001B[49m\u001B[43m[\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1899\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1900\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001B[0m, in \u001B[0;36mCParserWrapper.__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype_backend\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyarrow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;66;03m# Fail here loudly instead of in cython after reading\u001B[39;00m\n\u001B[1;32m     92\u001B[0m     import_optional_dependency(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyarrow\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 93\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader \u001B[38;5;241m=\u001B[39m \u001B[43mparsers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTextReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munnamed_cols \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader\u001B[38;5;241m.\u001B[39munnamed_cols\n\u001B[1;32m     97\u001B[0m \u001B[38;5;66;03m# error: Cannot determine type of 'names'\u001B[39;00m\n",
      "File \u001B[0;32mparsers.pyx:574\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:663\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._get_header\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:874\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:891\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:2053\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0xb0 in position 37: invalid start byte"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T04:07:06.997755Z",
     "start_time": "2024-07-29T04:07:05.908754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes=[]\n",
    "def read_csv_with_encoding(filepath):\n",
    "    encodings = ['utf-8', 'ISO-8859-1', 'latin1', 'cp1252']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, encoding=encoding)\n",
    "            return df\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(f\"Unable to read the file {filepath} with available encodings.\")\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        # Read the CSV file into a DataFrame with encoding handling\n",
    "        df = read_csv_with_encoding(filepath)\n",
    "        # Append the DataFrame to the list\n",
    "        dataframes.append(df)"
   ],
   "id": "ff5a490d87d5a350",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T04:07:10.315096Z",
     "start_time": "2024-07-29T04:07:10.234228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate all DataFrames in the list\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_filepath = '/Volumes/TOSHIBA EXT/parks_all/fca_cutoff_1100_all.csv'\n",
    "merged_df.to_csv(output_filepath, index=False)\n",
    "\n",
    "print(f\"Merged CSV file saved to {output_filepath}\")"
   ],
   "id": "cd3a30b563933540",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV file saved to /Volumes/TOSHIBA EXT/parks_all/fca_cutoff_1100_all.csv\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T09:55:23.640474Z",
     "start_time": "2024-07-30T09:55:23.616237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data for the table\n",
    "data_responsibility = {\n",
    "    \"Cloud Service Models\": [\"IaaS\", \"PaaS\"],\n",
    "    \"Erfys Confectionary is responsible for\": [\n",
    "        \"Data management and encryption.\\nAccess control and IAM policies.\\nApplication security and configuration.\",\n",
    "        \"Data management and encryption.\\nAccess control and IAM policies.\\nApplication configuration and management.\"\n",
    "    ],\n",
    "    \"AWS Cloud Service is responsible for\": [\n",
    "        \"Physical infrastructure security.\\nNetwork and virtualization security.\\nHardware maintenance and patching.\",\n",
    "        \"Physical infrastructure security.\\nOperating system and middleware management.\\nDatabase engine management and patching.\"\n",
    "    ],\n",
    "    \"User (Customer) is responsible for\": [\n",
    "        \"Securing the guest operating system (OS).\\nPatching the guest OS and applications.\\nConfiguring security group firewalls.\",\n",
    "        \"Managing access permissions (IAM).\\nConfiguring application settings.\\nImplementing data privacy and compliance controls.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_responsibility = pd.DataFrame(data_responsibility)\n",
    "\n",
    "# Path to save the CSV\n",
    "csv_responsibility_path = \"cloud_service_responsibility.csv\"\n",
    "df_responsibility.to_csv(csv_responsibility_path, index=False)\n",
    "\n",
    "csv_responsibility_path\n"
   ],
   "id": "cabc84004289408f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cloud_service_responsibility.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4dac3a0f04ecf0ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
