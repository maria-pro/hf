{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction to `transformers`\n",
    "\n",
    "💡 **Question 1**: I have a sentence below and how can I analyse it with `transformers`.\n",
    "\n",
    "**Question 2**: We have a dataset with a text file and we want to quickly extract themes and sentiments to have a \"feel\" of the data.\n",
    "\n",
    "**What we will cover**:\n",
    "\n",
    "- Install `transformers` library\n",
    "- Work with `pipeline`\n",
    "- Work with Hugging Face datasets\n",
    "\n",
    "In this activity, we are going to start working with the `transformers` library and have a look at its key function, `pipeline`.\n",
    "\n",
    "## Pipeline function\n",
    "\n",
    "The pipeline function in the Hugging Face Transformers library is a high-level API that simplifies the process of using pre-trained models for various NLP tasks.\n",
    "\n",
    "It abstracts away much of the complexity involved in loading models (e.g. tokenizing input, and processing output) and perform tasks like text classification, named entity recognition, sentiment analysis, question answering, translation, and more with just a few lines of code.\n",
    "\n",
    "### Install required libraries and load your text"
   ],
   "id": "13f0b585736b8a51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T18:07:10.252323Z",
     "start_time": "2024-08-11T18:07:08.606722Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install transformers datasets torch",
   "id": "8ceccb294a8e6402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (4.43.3)\r\n",
      "Requirement already satisfied: datasets in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (2.19.2)\r\n",
      "Requirement already satisfied: torch in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: filelock in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers) (3.14.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers) (0.23.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers) (2024.7.24)\r\n",
      "Requirement already satisfied: requests in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers) (4.66.4)\r\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from datasets) (16.1.0)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from datasets) (2.2.2)\r\n",
      "Requirement already satisfied: xxhash in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\r\n",
      "Requirement already satisfied: aiohttp in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from datasets) (3.9.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from torch) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests->transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests->transformers) (2024.6.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We will import specific functions from `transformers` library that we will use in this tutorial:\n",
    "\n",
    "- `pipeline()`: A function for various NLP tasks such as sentiment analysis, text classification, etc.\n",
    "\n",
    "- `AutoTokenizer`: A class that automatically loads the appropriate tokenizer for a given model.\n",
    "\n",
    "- `AutoModelForSequenceClassification`: A class that automatically loads the appropriate model for sequence classification tasks.\n"
   ],
   "id": "5cba72bd63fad640"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T22:22:17.073273Z",
     "start_time": "2024-08-11T22:22:17.070425Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification",
   "id": "e5f8365d5fe8ab43",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LLM is resource intensive so GPU is preferred. ",
   "id": "c5318e899d2fd7f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T22:22:18.339225Z",
     "start_time": "2024-08-11T22:22:18.336523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = 0 if torch.cuda.is_available() else -1"
   ],
   "id": "4ad04350505c7e4a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will experiment with this text, feel free to change it to your area!",
   "id": "e27987eb5e5c4aa4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T22:22:20.857700Z",
     "start_time": "2024-08-11T22:22:20.853873Z"
    }
   },
   "cell_type": "code",
   "source": "text=\"Cognitive behavioral therapy is a widely recommended treatment for managing anxiety and depression, helping individuals develop coping strategies to improve their mental health.\"",
   "id": "e9c9f65894589a51",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We import the pipeline function from the `transformers` library, create a text classification pipeline, specifying the device (GPU or CPU), and use the pipeline to classify the given text.\n",
    "\n",
    "The pipeline() method has the following structure: \n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# To use a default model & tokenizer for a given task(e.g. question-answering)\n",
    "pipeline(\"<task-name>\")\n",
    "\n",
    "# To use an existing model\n",
    "pipeline(\"<task-name>\", model=\"<model_name>\")\n",
    "\n",
    "# To use a custom model/tokenizer\n",
    "pipeline('<task-name>', model='<model name>',tokenizer='<tokenizer_name>')\n",
    "```\n",
    "Let's start with\n",
    "\n",
    "## Sentiment analysis \n"
   ],
   "id": "b648da47fe5ccb56"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = pipeline(\"text-classification\", device=device)\n",
    "result = classifier(text)\n",
    "print(result)\n"
   ],
   "id": "4dbe4d3ab47ef31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You may see this warning when you run:\n",
    "\n",
    "```python\n",
    "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
    "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
    "```\n",
    "\n",
    "When you use the pipeline function without specifying a model and revision, the `transformers `library defaults to a pre-configured model for the specified task. This is designed to make it easier for users to get started quickly without needing to know the details of which model and version of this model (`revision`) to use.  \n",
    "\n",
    "For example, if you create a text classification pipeline without specifying a model, it defaults to using the `distilbert/distilbert-base-uncased-finetuned-sst-2-english` model for sentiment analysis.\n",
    "\n",
    "For production environments, it is better to explicitly specify the model and its revision to ensure consistency and avoid unexpected changes in behavior due to updates in the default model."
   ],
   "id": "a86e6ed2d8361f21"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So we can run it with a different model:\n",
    "\n",
    "`FacebookAI/roberta-large-mnli`: an optimized version of BERT, fine-tuned on a larger dataset compared to BERT, including the Common Crawl dataset \n",
    "\n",
    "*Common Crawl dataset: a large-scale web dataset that contains petabytes of web data collected over several years. It includes raw web page data, metadata, and text extractions)*\n",
    "\n",
    "`cardiffnlp/twitter-roberta-base-sentiment`: A RoBERTa model fine-tuned on Twitter data for sentiment analysis."
   ],
   "id": "ea42179ea3a405cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T23:56:31.785575Z",
     "start_time": "2024-08-11T23:56:31.625056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# FacebookAI/roberta-large-mnl\n",
    "classifier = pipeline(\"text-classification\",\n",
    "                      model=\"FacebookAI/roberta-large-mnli\", device=device)\n",
    "result = classifier(text)\n",
    "print(result) "
   ],
   "id": "58fc990a2319cf9a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m classifier \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-classification\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      2\u001B[0m                       model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFacebookAI/roberta-large-mnli\u001B[39m\u001B[38;5;124m\"\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m      3\u001B[0m result \u001B[38;5;241m=\u001B[39m classifier(text)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(result) \n",
      "\u001B[0;31mNameError\u001B[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# cardiffnlp/twitter-roberta-base-sentiment\n",
    "classifier = pipeline(\"text-classification\",\n",
    "                      model=\"cardiffnlp/twitter-roberta-base-sentiment\", device=device)\n",
    "result = classifier(text)\n",
    "print(result)   "
   ],
   "id": "e412479b28f89b0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "if you have several texts, they use the list:",
   "id": "adc00f9f3fb90eb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "text2=\"Former President Donald Trump is struggling with an attack strategy against Kamala Harris, amid reports he called her a “b**ch” repeatedly in private as the Republican presidential nominee also sees support in the polls plunge.\"",
   "id": "16ebc2339bb80491"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "classifier = pipeline(\"text-classification\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", device=device)\n",
    "result = classifier([text, text2])\n",
    "print(result) "
   ],
   "id": "35f5d5c12b778346"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "or with a dataset, such as `ag_news` [here](https://paperswithcode.com/dataset/ag-news) and also on [Hugging Face](https://huggingface.co/datasets/fancyzhx/ag_news)\n",
    "\n",
    "![PaperWithCode](../images/ag_news.png)"
   ],
   "id": "70870dc72c5ed48e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a sample dataset (you can replace this with your own dataset)\n",
    "dataset = load_dataset('ag_news', split='train[:10]')  # Using a subset for demonstration"
   ],
   "id": "629ff0b90765b7d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using it with pipeline function:",
   "id": "150b7ecab78cbe6d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the sentiment analysis pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", revision=\"af0f99b\", device=device)\n",
    "\n"
   ],
   "id": "a22a9d9c49691c29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply the pipeline to each text in the dataset\n",
    "results = [classifier(item['text']) for item in dataset]\n",
    "\n",
    "# Print the results\n",
    "for result in results:\n",
    "    print(result)"
   ],
   "id": "73b97a695c5608c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Some other \n",
    "currently available pipelines are:\n",
    "\n",
    "- zero-shot-classification\n",
    "- feature-extraction (get the vector representation of a text)\n",
    "- fill-mask\n",
    "- ner (named entity recognition)\n",
    "- question-answering\n",
    "- sentiment-analysis\n",
    "- summarization\n",
    "- text-generation\n",
    "- translation\n",
    "\n",
    "\n",
    "Let's try them!\n",
    "\n",
    "## Zero-shot classification\n",
    "\n",
    "Most of the time, training an ML model requires all the possible labels/targets to be known beforehand (e.g. you have a dataset which is manually labelled), e.g. each news is assigned to a limited number of topics (e.g. science, politics, or education).\n",
    "\n",
    "What if your dataset has NO labels, but you have some ideas which labels can be used? \n",
    "\n",
    " "
   ],
   "id": "38f39891529fd7ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "candidate_labels = [\"economy\", \"health\", \"education\", \"foreign policy\", \"environment\", \"technology\", \"social justice\"]",
   "id": "bdda2cf617971a8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the zero-shot classification pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n"
   ],
   "id": "aaf10e9a4e91b39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply the pipeline to each text in the dataset\n",
    "results = [classifier(item['text'], candidate_labels=candidate_labels) for item in dataset]\n",
    "\n",
    "# Print the results\n",
    "for result in results:\n",
    "    print(result)"
   ],
   "id": "18489b92f7d48eee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the sentiment analysis pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "                      revision=\"af0f99b\", device=device)\n",
    "\n",
    "# Apply the pipeline to each text in the dataset\n",
    "results = [classifier(item['text']) for item in dataset]\n",
    "\n",
    "# Print the results\n",
    "for result in results:\n",
    "    print(result)"
   ],
   "id": "1576b323c0227711"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "complete",
   "id": "53d893d77acb34b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Question Answering\n",
    "\n",
    "Imagine writing a comprehensive literature review that spans hundreds of research papers, each filled with detailed analyses and discussions. You might want to prepare a table that specifies a sample size in the reviewed paper, methods used, timeframe for data collection and key findings. Instead of manually reading through each paper, you can use a question-answering model. This tool will quickly extract and present the exact information you're looking for across all the papers, streamlining your literature review process and allowing you to concentrate on synthesizing the research.\n",
    "\n",
    "What we need:\n",
    "\n",
    "- provide a model with proper context (collected of papers to review)\n",
    "- question we are interested in finding the answer to (e.g What is the sample size in this research?)\n",
    "\n"
   ],
   "id": "19dc0d2b5b27fa05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import the question-answering class and tokenizer from transformers\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer"
   ],
   "id": "dce51e21163c8de5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Specify the model and its tokenizer (notice that the model name and the tokenizer are the same)",
   "id": "255dd7733f26135"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "task = 'question-answering'\n",
    "QA_model = pipeline(task, model=model, tokenizer=model)"
   ],
   "id": "d0e1c2dba7207ad6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "QA_input = {\n",
    "          'question': 'when is Apple hosting an event?',\n",
    "          'context': dataset[-1]\n",
    "          }"
   ],
   "id": "5620f0f8e5e67003"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_response = QA_model(QA_input)\n",
    "pd.DataFrame([model_response])"
   ],
   "id": "1f52c0abd4c7f7a5"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "dataset[-1]",
   "id": "71eed9da985a3563",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "353221aa2c750777"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_kernel",
   "language": "python",
   "name": "ml_env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
