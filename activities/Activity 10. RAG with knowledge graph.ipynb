{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://www.datacamp.com/tutorial/knowledge-graph-rag",
   "id": "1697eac094113843"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Knowledge graph: https://neo4j.com/blog/what-is-knowledge-graph/\n",
    "GraphRAG Step by Step Tutorial: A step-by-step tutorial to build a Knowledge Graph-based RAG application with a Colab notebook. In this tutorial, you will learn how to extract knowledge from a text corpus, build a Knowledge Graph, store the Knowledge Graph in TiDB Serverless, and search from the Knowledge Graph."
   ],
   "id": "2bcbbd8012718e76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T17:56:12.735008Z",
     "start_time": "2024-08-12T17:55:50.554764Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install llama-index",
   "id": "2dd59181691cc407",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\r\n",
      "  Downloading llama_index-0.10.65-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\r\n",
      "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\r\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\r\n",
      "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting llama-index-core<0.11.0,>=0.10.65 (from llama-index)\r\n",
      "  Downloading llama_index_core-0.10.65-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\r\n",
      "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\r\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\r\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\r\n",
      "  Downloading llama_index_legacy-0.9.48.post1-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index)\r\n",
      "  Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl.metadata (650 bytes)\r\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\r\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\r\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\r\n",
      "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\r\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\r\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\r\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\r\n",
      "  Downloading llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\r\n",
      "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\r\n",
      "  Downloading openai-1.40.4-py3-none-any.whl.metadata (22 kB)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (6.0.1)\r\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Downloading SQLAlchemy-2.0.32-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.6 kB)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (3.9.5)\r\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.3.1)\r\n",
      "Requirement already satisfied: httpx in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (0.27.0)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (3.2.1)\r\n",
      "Collecting nltk>=3.8.2 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Downloading nltk-3.8.2-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2.2.2)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (10.3.0)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2.32.3)\r\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Downloading tiktoken-0.7.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (4.12.2)\r\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: wrapt in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.16.0)\r\n",
      "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\r\n",
      "  Downloading llama_cloud-0.0.13-py3-none-any.whl.metadata (751 bytes)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\r\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\r\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\r\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\r\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\r\n",
      "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (4.0.3)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\r\n",
      "Collecting pydantic>=1.10 (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\r\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\r\n",
      "Requirement already satisfied: anyio in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (4.4.0)\r\n",
      "Requirement already satisfied: certifi in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (0.14.0)\r\n",
      "Requirement already satisfied: click in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama-index) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.7.24)\r\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\r\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\r\n",
      "  Downloading jiter-0.5.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.26.16)\r\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Downloading greenlet-3.0.3-cp39-cp39-macosx_11_0_universal2.whl.metadata (3.8 kB)\r\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.65->llama-index)\r\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.2.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.65->llama-index) (24.1)\r\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\r\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting pydantic-core==2.20.1 (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\r\n",
      "  Downloading pydantic_core-2.20.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.16.0)\r\n",
      "Downloading llama_index-0.10.65-py3-none-any.whl (6.8 kB)\r\n",
      "Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\r\n",
      "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\r\n",
      "Downloading llama_index_core-0.10.65-py3-none-any.whl (15.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.5/15.5 MB\u001B[0m \u001B[31m7.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\r\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\r\n",
      "Downloading llama_index_legacy-0.9.48.post1-py3-none-any.whl (1.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading llama_index_llms_openai-0.1.29-py3-none-any.whl (11 kB)\r\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\r\n",
      "Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\r\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\r\n",
      "Downloading llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\r\n",
      "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\r\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\r\n",
      "Downloading llama_cloud-0.0.13-py3-none-any.whl (169 kB)\r\n",
      "Downloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\r\n",
      "Downloading nltk-3.8.2-py3-none-any.whl (1.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading openai-1.40.4-py3-none-any.whl (361 kB)\r\n",
      "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\r\n",
      "Downloading SQLAlchemy-2.0.32-cp39-cp39-macosx_11_0_arm64.whl (2.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m10.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\r\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\r\n",
      "Downloading tiktoken-0.7.0-cp39-cp39-macosx_11_0_arm64.whl (907 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m907.9/907.9 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\r\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\r\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\r\n",
      "Downloading greenlet-3.0.3-cp39-cp39-macosx_11_0_universal2.whl (269 kB)\r\n",
      "Downloading jiter-0.5.0-cp39-cp39-macosx_11_0_arm64.whl (283 kB)\r\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\r\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\r\n",
      "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\r\n",
      "Downloading pydantic_core-2.20.1-cp39-cp39-macosx_11_0_arm64.whl (1.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Installing collected packages: striprtf, dirtyjson, tenacity, SQLAlchemy, pypdf, pydantic-core, nltk, mypy-extensions, marshmallow, jiter, greenlet, distro, deprecated, annotated-types, typing-inspect, tiktoken, pydantic, openai, llama-cloud, dataclasses-json, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\r\n",
      "  Attempting uninstall: tenacity\r\n",
      "    Found existing installation: tenacity 9.0.0\r\n",
      "    Uninstalling tenacity-9.0.0:\r\n",
      "      Successfully uninstalled tenacity-9.0.0\r\n",
      "  Attempting uninstall: nltk\r\n",
      "    Found existing installation: nltk 3.8.1\r\n",
      "    Uninstalling nltk-3.8.1:\r\n",
      "      Successfully uninstalled nltk-3.8.1\r\n",
      "Successfully installed SQLAlchemy-2.0.32 annotated-types-0.7.0 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 greenlet-3.0.3 jiter-0.5.0 llama-cloud-0.0.13 llama-index-0.10.65 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.65 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48.post1 llama-index-llms-openai-0.1.29 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 marshmallow-3.21.3 mypy-extensions-1.0.0 nltk-3.8.2 openai-1.40.4 pydantic-2.8.2 pydantic-core-2.20.1 pypdf-4.3.1 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By default, LlamaIndex uses OpenAI GPT-3 text-davinci-003 model. To use this model, you must have an OPENAI_API_KEY setup. You can create a free account and get an API key by logging into [OpenAI’s new API token](https://platform.openai.com/api-keys).",
   "id": "95bc47723369565f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:07:37.479155Z",
     "start_time": "2024-08-13T00:07:37.476416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n"
   ],
   "id": "85a2e11727efff1b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T18:00:18.320517Z",
     "start_time": "2024-08-12T18:00:16.840642Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install openai",
   "id": "8f5905ccab37193c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (1.40.4)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (2.8.2)\r\n",
      "Requirement already satisfied: sniffio in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (4.12.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\r\n",
      "Requirement already satisfied: certifi in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T18:00:49.991495Z",
     "start_time": "2024-08-12T18:00:48.434671Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install llama-index openai pypdf",
   "id": "18d0fd60c39ac4b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (0.10.65)\r\n",
      "Requirement already satisfied: openai in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (1.40.4)\r\n",
      "Requirement already satisfied: pypdf in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (4.3.1)\r\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.2.9)\r\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.1.13)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.65 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.10.65)\r\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.1.11)\r\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.2.7)\r\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.9.48.post1)\r\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.27 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.1.29)\r\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.1.9)\r\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.1.7)\r\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.1.3)\r\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.1.33)\r\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index) (0.1.6)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (2.8.2)\r\n",
      "Requirement already satisfied: sniffio in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai) (4.12.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\r\n",
      "Requirement already satisfied: certifi in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.0.32)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.3.1)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (3.2.1)\r\n",
      "Requirement already satisfied: nltk>=3.8.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (3.8.2)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2.2.2)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (10.3.0)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (0.7.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.16.0)\r\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.0.13)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\r\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\r\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-readers-llama-parse>=0.1.2->llama-index) (0.4.9)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (4.0.3)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\r\n",
      "Requirement already satisfied: click in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama-index) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.7.24)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.26.16)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.21.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.65->llama-index) (24.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.16.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:08:11.038707Z",
     "start_time": "2024-08-13T00:08:10.940631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import TreeIndex, SimpleDirectoryReader\n",
    "\n",
    "resume = SimpleDirectoryReader(\"Private-Data\").load_data()\n",
    "new_index = TreeIndex.from_documents(resume)"
   ],
   "id": "363befc62810b815",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:08:14.914350Z",
     "start_time": "2024-08-13T00:08:14.736066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import SimpleDirectoryReader, TreeIndex\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"/Users/e5028514/Desktop/Projects/HF/activities/Private-Data\").load_data()\n",
    "new_index = TreeIndex.from_documents(reader)"
   ],
   "id": "82e6c61d8e1e30d4",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:08:44.533921Z",
     "start_time": "2024-08-13T00:08:19.755418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_engine = new_index.as_query_engine()\n",
    "response = query_engine.query(\"What is save_pretrained()?\")\n",
    "print(response)"
   ],
   "id": "fe52598cff073d44",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.4178054095510232 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 1.3395290827828839 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRateLimitError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m query_engine \u001B[38;5;241m=\u001B[39m new_index\u001B[38;5;241m.\u001B[39mas_query_engine()\n\u001B[0;32m----> 2\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mquery_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWhat is save_pretrained()?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(response)\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/base/base_query_engine.py:52\u001B[0m, in \u001B[0;36mBaseQueryEngine.query\u001B[0;34m(self, str_or_query_bundle)\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(str_or_query_bundle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     51\u001B[0m         str_or_query_bundle \u001B[38;5;241m=\u001B[39m QueryBundle(str_or_query_bundle)\n\u001B[0;32m---> 52\u001B[0m     query_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstr_or_query_bundle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m dispatcher\u001B[38;5;241m.\u001B[39mevent(\n\u001B[1;32m     54\u001B[0m     QueryEndEvent(query\u001B[38;5;241m=\u001B[39mstr_or_query_bundle, response\u001B[38;5;241m=\u001B[39mquery_result)\n\u001B[1;32m     55\u001B[0m )\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m query_result\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/query_engine/retriever_query_engine.py:189\u001B[0m, in \u001B[0;36mRetrieverQueryEngine._query\u001B[0;34m(self, query_bundle)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Answer a query.\"\"\"\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mevent(\n\u001B[1;32m    187\u001B[0m     CBEventType\u001B[38;5;241m.\u001B[39mQUERY, payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mQUERY_STR: query_bundle\u001B[38;5;241m.\u001B[39mquery_str}\n\u001B[1;32m    188\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m query_event:\n\u001B[0;32m--> 189\u001B[0m     nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_bundle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    190\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_response_synthesizer\u001B[38;5;241m.\u001B[39msynthesize(\n\u001B[1;32m    191\u001B[0m         query\u001B[38;5;241m=\u001B[39mquery_bundle,\n\u001B[1;32m    192\u001B[0m         nodes\u001B[38;5;241m=\u001B[39mnodes,\n\u001B[1;32m    193\u001B[0m     )\n\u001B[1;32m    194\u001B[0m     query_event\u001B[38;5;241m.\u001B[39mon_end(payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mRESPONSE: response})\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/query_engine/retriever_query_engine.py:144\u001B[0m, in \u001B[0;36mRetrieverQueryEngine.retrieve\u001B[0;34m(self, query_bundle)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mretrieve\u001B[39m(\u001B[38;5;28mself\u001B[39m, query_bundle: QueryBundle) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[NodeWithScore]:\n\u001B[0;32m--> 144\u001B[0m     nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retriever\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_bundle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_node_postprocessors(nodes, query_bundle\u001B[38;5;241m=\u001B[39mquery_bundle)\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/base/base_retriever.py:243\u001B[0m, in \u001B[0;36mBaseRetriever.retrieve\u001B[0;34m(self, str_or_query_bundle)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mas_trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mevent(\n\u001B[1;32m    240\u001B[0m         CBEventType\u001B[38;5;241m.\u001B[39mRETRIEVE,\n\u001B[1;32m    241\u001B[0m         payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mQUERY_STR: query_bundle\u001B[38;5;241m.\u001B[39mquery_str},\n\u001B[1;32m    242\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m retrieve_event:\n\u001B[0;32m--> 243\u001B[0m         nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_bundle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    244\u001B[0m         nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_recursive_retrieval(query_bundle, nodes)\n\u001B[1;32m    245\u001B[0m         retrieve_event\u001B[38;5;241m.\u001B[39mon_end(\n\u001B[1;32m    246\u001B[0m             payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mNODES: nodes},\n\u001B[1;32m    247\u001B[0m         )\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/indices/tree/select_leaf_retriever.py:425\u001B[0m, in \u001B[0;36mTreeSelectLeafRetriever._retrieve\u001B[0;34m(self, query_bundle)\u001B[0m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_retrieve\u001B[39m(\n\u001B[1;32m    421\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    422\u001B[0m     query_bundle: QueryBundle,\n\u001B[1;32m    423\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[NodeWithScore]:\n\u001B[1;32m    424\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get nodes for response.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 425\u001B[0m     nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retrieve_level\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_index_struct\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot_nodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_bundle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    430\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [NodeWithScore(node\u001B[38;5;241m=\u001B[39mnode) \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m nodes]\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/indices/tree/select_leaf_retriever.py:401\u001B[0m, in \u001B[0;36mTreeSelectLeafRetriever._retrieve_level\u001B[0;34m(self, cur_node_ids, query_bundle, level)\u001B[0m\n\u001B[1;32m    398\u001B[0m cur_node_list \u001B[38;5;241m=\u001B[39m get_sorted_node_list(cur_nodes)\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(cur_node_list) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchild_branch_factor:\n\u001B[0;32m--> 401\u001B[0m     selected_nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_select_nodes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcur_node_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_bundle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    407\u001B[0m     selected_nodes \u001B[38;5;241m=\u001B[39m cur_node_list\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/indices/tree/select_leaf_retriever.py:312\u001B[0m, in \u001B[0;36mTreeSelectLeafRetriever._select_nodes\u001B[0;34m(self, cur_node_list, query_bundle, level)\u001B[0m\n\u001B[1;32m    304\u001B[0m     text_splitter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prompt_helper\u001B[38;5;241m.\u001B[39mget_text_splitter_given_prompt(\n\u001B[1;32m    305\u001B[0m         prompt\u001B[38;5;241m=\u001B[39mquery_template,\n\u001B[1;32m    306\u001B[0m         num_chunks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(cur_node_list),\n\u001B[1;32m    307\u001B[0m     )\n\u001B[1;32m    308\u001B[0m     numbered_node_text \u001B[38;5;241m=\u001B[39m get_numbered_text_from_nodes(\n\u001B[1;32m    309\u001B[0m         cur_node_list, text_splitter\u001B[38;5;241m=\u001B[39mtext_splitter\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 312\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_llm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_template\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontext_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumbered_node_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    317\u001B[0m     query_template_multiple \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquery_template_multiple\u001B[38;5;241m.\u001B[39mpartial_format(\n\u001B[1;32m    318\u001B[0m         num_chunks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(cur_node_list),\n\u001B[1;32m    319\u001B[0m         query_str\u001B[38;5;241m=\u001B[39mquery_str,\n\u001B[1;32m    320\u001B[0m         branching_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchild_branch_factor,\n\u001B[1;32m    321\u001B[0m     )\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/llms/llm.py:559\u001B[0m, in \u001B[0;36mLLM.predict\u001B[0;34m(self, prompt, **prompt_args)\u001B[0m\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata\u001B[38;5;241m.\u001B[39mis_chat_model:\n\u001B[1;32m    558\u001B[0m     messages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_messages(prompt, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mprompt_args)\n\u001B[0;32m--> 559\u001B[0m     chat_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    560\u001B[0m     output \u001B[38;5;241m=\u001B[39m chat_response\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mcontent \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/llms/callbacks.py:172\u001B[0m, in \u001B[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001B[0;34m(_self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    163\u001B[0m event_id \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_event_start(\n\u001B[1;32m    164\u001B[0m     CBEventType\u001B[38;5;241m.\u001B[39mLLM,\n\u001B[1;32m    165\u001B[0m     payload\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    169\u001B[0m     },\n\u001B[1;32m    170\u001B[0m )\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 172\u001B[0m     f_return_val \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_self\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    174\u001B[0m     callback_manager\u001B[38;5;241m.\u001B[39mon_event_end(\n\u001B[1;32m    175\u001B[0m         CBEventType\u001B[38;5;241m.\u001B[39mLLM,\n\u001B[1;32m    176\u001B[0m         payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mEXCEPTION: e},\n\u001B[1;32m    177\u001B[0m         event_id\u001B[38;5;241m=\u001B[39mevent_id,\n\u001B[1;32m    178\u001B[0m     )\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/llms/openai/base.py:333\u001B[0m, in \u001B[0;36mOpenAI.chat\u001B[0;34m(self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    332\u001B[0m     chat_fn \u001B[38;5;241m=\u001B[39m completion_to_chat_decorator(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_complete)\n\u001B[0;32m--> 333\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mchat_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/llms/openai/base.py:95\u001B[0m, in \u001B[0;36mllm_retry_decorator.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     88\u001B[0m retry \u001B[38;5;241m=\u001B[39m create_retry_decorator(\n\u001B[1;32m     89\u001B[0m     max_retries\u001B[38;5;241m=\u001B[39mmax_retries,\n\u001B[1;32m     90\u001B[0m     random_exponential\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     93\u001B[0m     max_seconds\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m,\n\u001B[1;32m     94\u001B[0m )\n\u001B[0;32m---> 95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretry\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:336\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    334\u001B[0m copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    335\u001B[0m wrapped_f\u001B[38;5;241m.\u001B[39mstatistics \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mstatistics  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m--> 336\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:475\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    473\u001B[0m retry_state \u001B[38;5;241m=\u001B[39m RetryCallState(retry_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, fn\u001B[38;5;241m=\u001B[39mfn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 475\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    476\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[1;32m    477\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:376\u001B[0m, in \u001B[0;36mBaseRetrying.iter\u001B[0;34m(self, retry_state)\u001B[0m\n\u001B[1;32m    374\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m action \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_state\u001B[38;5;241m.\u001B[39mactions:\n\u001B[0;32m--> 376\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43maction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:418\u001B[0m, in \u001B[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001B[0;34m(rs)\u001B[0m\n\u001B[1;32m    416\u001B[0m retry_exc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_error_cls(fut)\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreraise:\n\u001B[0;32m--> 418\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[43mretry_exc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m retry_exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfut\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexception\u001B[39;00m()\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:185\u001B[0m, in \u001B[0;36mRetryError.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreraise\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mNoReturn:\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_attempt\u001B[38;5;241m.\u001B[39mfailed:\n\u001B[0;32m--> 185\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlast_attempt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:438\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 438\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 390\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    393\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:478\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[1;32m    477\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 478\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    479\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n\u001B[1;32m    480\u001B[0m         retry_state\u001B[38;5;241m.\u001B[39mset_exception(sys\u001B[38;5;241m.\u001B[39mexc_info())  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/llms/openai/base.py:401\u001B[0m, in \u001B[0;36mOpenAI._chat\u001B[0;34m(self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    398\u001B[0m message_dicts \u001B[38;5;241m=\u001B[39m to_openai_message_dicts(messages)\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreuse_client:\n\u001B[0;32m--> 401\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessage_dicts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_model_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    407\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m client:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_utils/_utils.py:274\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    272\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 274\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/resources/chat/completions.py:668\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    635\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    665\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    666\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m    667\u001B[0m     validate_response_format(response_format)\n\u001B[0;32m--> 668\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    683\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    684\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    686\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    687\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    689\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    695\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    696\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    699\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    700\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    701\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1259\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1246\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1247\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1254\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1255\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1256\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1257\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1258\u001B[0m     )\n\u001B[0;32m-> 1259\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:936\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    927\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    928\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    929\u001B[0m     cast_to: Type[ResponseT],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    934\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    935\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m--> 936\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    937\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    938\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    939\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    940\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    941\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    942\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1025\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1024\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1025\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m        \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1031\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1032\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1074\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1074\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1025\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1024\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1025\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m        \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1031\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1032\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1074\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1074\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1025\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1024\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1025\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m        \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1031\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1032\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1074\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1074\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1040\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1037\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1039\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1040\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1042\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1043\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1044\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1048\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39moptions\u001B[38;5;241m.\u001B[39mget_max_retries(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_retries) \u001B[38;5;241m-\u001B[39m retries,\n\u001B[1;32m   1049\u001B[0m )\n",
      "\u001B[0;31mRateLimitError\u001B[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e8ffa470c1318575"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:14:29.996793Z",
     "start_time": "2024-08-13T00:14:29.107268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"/Users/e5028514/Desktop/Projects/HF/activities/Private-Data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ],
   "id": "5d12bca2fa1bc758",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:14:38.332621Z",
     "start_time": "2024-08-13T00:14:38.327621Z"
    }
   },
   "cell_type": "code",
   "source": "index",
   "id": "9ad15e7550cbb4b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x178d010a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:15:15.700718Z",
     "start_time": "2024-08-13T00:14:52.258180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ],
   "id": "193c3f5d449ae4a0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9515968327076059 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.07678573698121371 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRateLimitError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m query_engine \u001B[38;5;241m=\u001B[39m index\u001B[38;5;241m.\u001B[39mas_query_engine()\n\u001B[0;32m----> 2\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mquery_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWhat did the author do growing up?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(response)\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/base/base_query_engine.py:52\u001B[0m, in \u001B[0;36mBaseQueryEngine.query\u001B[0;34m(self, str_or_query_bundle)\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(str_or_query_bundle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     51\u001B[0m         str_or_query_bundle \u001B[38;5;241m=\u001B[39m QueryBundle(str_or_query_bundle)\n\u001B[0;32m---> 52\u001B[0m     query_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstr_or_query_bundle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m dispatcher\u001B[38;5;241m.\u001B[39mevent(\n\u001B[1;32m     54\u001B[0m     QueryEndEvent(query\u001B[38;5;241m=\u001B[39mstr_or_query_bundle, response\u001B[38;5;241m=\u001B[39mquery_result)\n\u001B[1;32m     55\u001B[0m )\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m query_result\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/query_engine/retriever_query_engine.py:190\u001B[0m, in \u001B[0;36mRetrieverQueryEngine._query\u001B[0;34m(self, query_bundle)\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mevent(\n\u001B[1;32m    187\u001B[0m     CBEventType\u001B[38;5;241m.\u001B[39mQUERY, payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mQUERY_STR: query_bundle\u001B[38;5;241m.\u001B[39mquery_str}\n\u001B[1;32m    188\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m query_event:\n\u001B[1;32m    189\u001B[0m     nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretrieve(query_bundle)\n\u001B[0;32m--> 190\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_response_synthesizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msynthesize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_bundle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    194\u001B[0m     query_event\u001B[38;5;241m.\u001B[39mon_end(payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mRESPONSE: response})\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/base.py:251\u001B[0m, in \u001B[0;36mBaseSynthesizer.synthesize\u001B[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001B[0m\n\u001B[1;32m    245\u001B[0m     query \u001B[38;5;241m=\u001B[39m QueryBundle(query_str\u001B[38;5;241m=\u001B[39mquery)\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback_manager\u001B[38;5;241m.\u001B[39mevent(\n\u001B[1;32m    248\u001B[0m     CBEventType\u001B[38;5;241m.\u001B[39mSYNTHESIZE,\n\u001B[1;32m    249\u001B[0m     payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mQUERY_STR: query\u001B[38;5;241m.\u001B[39mquery_str},\n\u001B[1;32m    250\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m event:\n\u001B[0;32m--> 251\u001B[0m     response_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_response\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_str\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_str\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtext_chunks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetadata_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMetadataMode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLLM\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnodes\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    259\u001B[0m     additional_source_nodes \u001B[38;5;241m=\u001B[39m additional_source_nodes \u001B[38;5;129;01mor\u001B[39;00m []\n\u001B[1;32m    260\u001B[0m     source_nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(nodes) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(additional_source_nodes)\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py:43\u001B[0m, in \u001B[0;36mCompactAndRefine.get_response\u001B[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# use prompt helper to fix compact text_chunks under the prompt limitation\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# TODO: This is a temporary fix - reason it's temporary is that\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# the refine template does not account for size of previous answer.\u001B[39;00m\n\u001B[1;32m     42\u001B[0m new_texts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001B[0;32m---> 43\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_response\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery_str\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_str\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtext_chunks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_texts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprev_response\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprev_response\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py:183\u001B[0m, in \u001B[0;36mRefine.get_response\u001B[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001B[0m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m text_chunk \u001B[38;5;129;01min\u001B[39;00m text_chunks:\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m prev_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    181\u001B[0m         \u001B[38;5;66;03m# if this is the first chunk, and text chunk already\u001B[39;00m\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;66;03m# is an answer, then return it\u001B[39;00m\n\u001B[0;32m--> 183\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_give_response_single\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m            \u001B[49m\u001B[43mquery_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kwargs\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m         \u001B[38;5;66;03m# refine response if possible\u001B[39;00m\n\u001B[1;32m    188\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_refine_response_single(\n\u001B[1;32m    189\u001B[0m             prev_response, query_str, text_chunk, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresponse_kwargs\n\u001B[1;32m    190\u001B[0m         )\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py:238\u001B[0m, in \u001B[0;36mRefine._give_response_single\u001B[0;34m(self, query_str, text_chunk, **response_kwargs)\u001B[0m\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_streaming:\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m         structured_response \u001B[38;5;241m=\u001B[39m cast(\n\u001B[1;32m    237\u001B[0m             StructuredRefineResponse,\n\u001B[0;32m--> 238\u001B[0m             \u001B[43mprogram\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m                \u001B[49m\u001B[43mcontext_str\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcur_text_chunk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    242\u001B[0m         )\n\u001B[1;32m    243\u001B[0m         query_satisfied \u001B[38;5;241m=\u001B[39m structured_response\u001B[38;5;241m.\u001B[39mquery_satisfied\n\u001B[1;32m    244\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m query_satisfied:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/response_synthesizers/refine.py:84\u001B[0m, in \u001B[0;36mDefaultRefineProgram.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m     82\u001B[0m     answer \u001B[38;5;241m=\u001B[39m answer\u001B[38;5;241m.\u001B[39mjson()\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 84\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_llm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m StructuredRefineResponse(answer\u001B[38;5;241m=\u001B[39manswer, query_satisfied\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/llms/llm.py:559\u001B[0m, in \u001B[0;36mLLM.predict\u001B[0;34m(self, prompt, **prompt_args)\u001B[0m\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata\u001B[38;5;241m.\u001B[39mis_chat_model:\n\u001B[1;32m    558\u001B[0m     messages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_messages(prompt, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mprompt_args)\n\u001B[0;32m--> 559\u001B[0m     chat_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    560\u001B[0m     output \u001B[38;5;241m=\u001B[39m chat_response\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mcontent \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspan_enter(\n\u001B[1;32m    253\u001B[0m     id_\u001B[38;5;241m=\u001B[39mid_,\n\u001B[1;32m    254\u001B[0m     bound_args\u001B[38;5;241m=\u001B[39mbound_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    258\u001B[0m )\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent(SpanDropEvent(span_id\u001B[38;5;241m=\u001B[39mid_, err_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(e)))\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/core/llms/callbacks.py:172\u001B[0m, in \u001B[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001B[0;34m(_self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    163\u001B[0m event_id \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_event_start(\n\u001B[1;32m    164\u001B[0m     CBEventType\u001B[38;5;241m.\u001B[39mLLM,\n\u001B[1;32m    165\u001B[0m     payload\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    169\u001B[0m     },\n\u001B[1;32m    170\u001B[0m )\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 172\u001B[0m     f_return_val \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_self\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    174\u001B[0m     callback_manager\u001B[38;5;241m.\u001B[39mon_event_end(\n\u001B[1;32m    175\u001B[0m         CBEventType\u001B[38;5;241m.\u001B[39mLLM,\n\u001B[1;32m    176\u001B[0m         payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mEXCEPTION: e},\n\u001B[1;32m    177\u001B[0m         event_id\u001B[38;5;241m=\u001B[39mevent_id,\n\u001B[1;32m    178\u001B[0m     )\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/llms/openai/base.py:333\u001B[0m, in \u001B[0;36mOpenAI.chat\u001B[0;34m(self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    332\u001B[0m     chat_fn \u001B[38;5;241m=\u001B[39m completion_to_chat_decorator(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_complete)\n\u001B[0;32m--> 333\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mchat_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/llms/openai/base.py:95\u001B[0m, in \u001B[0;36mllm_retry_decorator.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     88\u001B[0m retry \u001B[38;5;241m=\u001B[39m create_retry_decorator(\n\u001B[1;32m     89\u001B[0m     max_retries\u001B[38;5;241m=\u001B[39mmax_retries,\n\u001B[1;32m     90\u001B[0m     random_exponential\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     93\u001B[0m     max_seconds\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m,\n\u001B[1;32m     94\u001B[0m )\n\u001B[0;32m---> 95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretry\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:336\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    334\u001B[0m copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    335\u001B[0m wrapped_f\u001B[38;5;241m.\u001B[39mstatistics \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mstatistics  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m--> 336\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:475\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    473\u001B[0m retry_state \u001B[38;5;241m=\u001B[39m RetryCallState(retry_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, fn\u001B[38;5;241m=\u001B[39mfn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 475\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    476\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[1;32m    477\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:376\u001B[0m, in \u001B[0;36mBaseRetrying.iter\u001B[0;34m(self, retry_state)\u001B[0m\n\u001B[1;32m    374\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m action \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_state\u001B[38;5;241m.\u001B[39mactions:\n\u001B[0;32m--> 376\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43maction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:418\u001B[0m, in \u001B[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001B[0;34m(rs)\u001B[0m\n\u001B[1;32m    416\u001B[0m retry_exc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_error_cls(fut)\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreraise:\n\u001B[0;32m--> 418\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[43mretry_exc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m retry_exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfut\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexception\u001B[39;00m()\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:185\u001B[0m, in \u001B[0;36mRetryError.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreraise\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mNoReturn:\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_attempt\u001B[38;5;241m.\u001B[39mfailed:\n\u001B[0;32m--> 185\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlast_attempt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:438\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 438\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 390\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    393\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/tenacity/__init__.py:478\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[1;32m    477\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 478\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    479\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n\u001B[1;32m    480\u001B[0m         retry_state\u001B[38;5;241m.\u001B[39mset_exception(sys\u001B[38;5;241m.\u001B[39mexc_info())  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/llama_index/llms/openai/base.py:401\u001B[0m, in \u001B[0;36mOpenAI._chat\u001B[0;34m(self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    398\u001B[0m message_dicts \u001B[38;5;241m=\u001B[39m to_openai_message_dicts(messages)\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreuse_client:\n\u001B[0;32m--> 401\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessage_dicts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_model_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    407\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m client:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_utils/_utils.py:274\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    272\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 274\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/resources/chat/completions.py:668\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    635\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    665\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    666\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m    667\u001B[0m     validate_response_format(response_format)\n\u001B[0;32m--> 668\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    683\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    684\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    686\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    687\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    689\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    695\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    696\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    699\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    700\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    701\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1259\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1246\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1247\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1254\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1255\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1256\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1257\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1258\u001B[0m     )\n\u001B[0;32m-> 1259\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:936\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    927\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    928\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    929\u001B[0m     cast_to: Type[ResponseT],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    934\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    935\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m--> 936\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    937\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    938\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    939\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    940\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    941\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    942\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1025\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1024\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1025\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m        \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1031\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1032\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1074\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1074\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1025\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1024\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1025\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m        \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1031\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1032\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1074\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1074\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1025\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1024\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1025\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m        \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1031\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1032\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1074\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1074\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/HF/.venv/lib/python3.9/site-packages/openai/_base_client.py:1040\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1037\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1039\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1040\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1042\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1043\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1044\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1048\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39moptions\u001B[38;5;241m.\u001B[39mget_max_retries(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_retries) \u001B[38;5;241m-\u001B[39m retries,\n\u001B[1;32m   1049\u001B[0m )\n",
      "\u001B[0;31mRateLimitError\u001B[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:21:24.122782Z",
     "start_time": "2024-08-13T00:21:21.518722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#trying ollama\n",
    "\n",
    "!pip install llama-index-llms-ollama"
   ],
   "id": "5d4cea1d2b024a61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-ollama\r\n",
      "  Downloading llama_index_llms_ollama-0.2.2-py3-none-any.whl.metadata (668 bytes)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-llms-ollama) (0.10.65)\r\n",
      "Collecting ollama>=0.3.0 (from llama-index-llms-ollama)\r\n",
      "  Downloading ollama-0.3.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.0.32)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2024.3.1)\r\n",
      "Requirement already satisfied: httpx in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.27.0)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.2.1)\r\n",
      "Requirement already satisfied: nltk>=3.8.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.8.2)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.26.4)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.40.4)\r\n",
      "Requirement already satisfied: pandas in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.2.2)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (10.3.0)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.7.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (4.12.2)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.16.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (4.0.3)\r\n",
      "Requirement already satisfied: anyio in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (4.4.0)\r\n",
      "Requirement already satisfied: certifi in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.14.0)\r\n",
      "Requirement already satisfied: click in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2024.7.24)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.8.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.26.16)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (3.21.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2024.1)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.2.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (24.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (2.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama) (1.16.0)\r\n",
      "Downloading llama_index_llms_ollama-0.2.2-py3-none-any.whl (4.4 kB)\r\n",
      "Downloading ollama-0.3.1-py3-none-any.whl (10 kB)\r\n",
      "Installing collected packages: ollama, llama-index-llms-ollama\r\n",
      "Successfully installed llama-index-llms-ollama-0.2.2 ollama-0.3.1\r\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:21:52.159424Z",
     "start_time": "2024-08-13T00:21:49.528259Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install llama-index-embeddings-huggingface\n",
   "id": "9c2bf69d1c66b7fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface\r\n",
      "  Downloading llama_index_embeddings_huggingface-0.2.3-py3-none-any.whl.metadata (769 bytes)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.23.3)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-embeddings-huggingface) (0.10.65)\r\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-embeddings-huggingface) (3.0.1)\r\n",
      "Requirement already satisfied: filelock in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.14.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.3.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\r\n",
      "Requirement already satisfied: requests in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\r\n",
      "Requirement already satisfied: aiohttp in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.5)\r\n",
      "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\r\n",
      "  Downloading minijinja-2.0.1-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (8.8 kB)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.32)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\r\n",
      "Requirement already satisfied: httpx in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.2.1)\r\n",
      "Requirement already satisfied: nltk>=3.8.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.2)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.26.4)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.40.4)\r\n",
      "Requirement already satisfied: pandas in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.2.2)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (10.3.0)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.7.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.43.3)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.3.1)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.1)\r\n",
      "Requirement already satisfied: scipy in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\r\n",
      "Requirement already satisfied: click in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.7.24)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.8.2)\r\n",
      "Requirement already satisfied: sniffio in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.1)\r\n",
      "Requirement already satisfied: certifi in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.26.16)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.0.3)\r\n",
      "Requirement already satisfied: sympy in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.12.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.19.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/e5028514/Desktop/Projects/HF/.venv/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\r\n",
      "Downloading llama_index_embeddings_huggingface-0.2.3-py3-none-any.whl (8.6 kB)\r\n",
      "Downloading minijinja-2.0.1-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (1.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m11.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: minijinja, llama-index-embeddings-huggingface\r\n",
      "Successfully installed llama-index-embeddings-huggingface-0.2.3 minijinja-2.0.1\r\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:23:55.915992Z",
     "start_time": "2024-08-13T00:23:07.966859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "documents = SimpleDirectoryReader(\"/Users/e5028514/Desktop/Projects/HF/activities/Private-Data\").load_data()\n",
    "\n",
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# ollama\n",
    "Settings.llm = Ollama(model=\"llama3\", request_timeout=360.0)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    ")"
   ],
   "id": "51a5c5828a845306",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d32f24bbd0834a5ea721a9143aec45b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b84afc17bc584109aa0604b4265b6f1c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ecefebb76734566b1fe4836f3f3f3df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12d0978424e844f789c284f70ebac8c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72d0a7c9b369414eb38bb4713e6a0818"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d77a9d898c64ec39c6778d55a786256"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c755cca77c644c1f8178d8716d5d06aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a2c0af51f4e43e1937372356a9fbea7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "470ed9d0454d4ed5aecd809bd7b993a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce4aa668b41e4a4bbae10794b0e4c164"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d86088470c64ec49f373c4fbe548035"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T00:24:36.982385Z",
     "start_time": "2024-08-13T00:24:10.531558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ],
   "id": "1e2ac3ce7d483c2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before college, the author worked on writing short stories and programming. He wrote his first programs in an early version of Fortran on an IBM 1401 at his junior high school, and later built a microcomputer kit by Heathkit with his friend. The author also started programming more seriously when he got a TRS-80 computer in about 1980.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a441bd8644c59bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
